internal error during opening a hprof file. null user-agent:       mozilla/ (x11; u; linux x86_64; en-us; rv:.) gecko/2009090217 ubuntu/ (jaunty) firefox/.14 build identifier: .  i've tried to open a big ( gb) hprof dump file, which i've collected from sun-. jvm, but after minutes of parsing, it stops with an internal error:  java.lang.arrayindexoutofboundsexception: 10735825 at org.eclipse.mat.parser.internal.dominatortree$calculator.dfs(dominatortree.java:  at org.eclipse.mat.parser.internal.dominatortree$calculator.compute(dominatortree.java:  at org.eclipse.mat.parser.internal.dominatortree.calculate(dominatortree.java:  at org.eclipse.mat.parser.internal.snapshotimpl.calculatedominatortree(snapshotimpl.java:  at org.eclipse.mat.parser.internal.snapshotfactoryimpl.parse(snapshotfactoryimpl.java:  at org.eclipse.mat.parser.internal.snapshotfactoryimpl.opensnapshot(snapshotfactoryimpl.java:  at org.eclipse.mat.snapshot.snapshotfactory.opensnapshot(snapshotfactory.java:  at org.eclipse.mat.snapshot.snapshotfactory.opensnapshot(snapshotfactory.java:  at org.eclipse.mat.ui.snapshot.parseheapdumpjob.run(parseheapdumpjob.java:  at org.eclipse.core.internal.jobs.worker.run(worker.java:   after closing the tab, and reopening a file it reports that dominator tree is not available, so most of the reports are not working. re-indexing not helps.    reproducible: always  steps to reproduce: 1. open a big heap dump 2. wait some minutes 3. internal error does this happen also with smaller dumps? i'm asking as it would be very helpful to have a heap dump which triggers the problem and look at it. or could you provide us this dump (i guess zipped it will be about 100 - 150mb). may be you can upload it somewhere?  i had a look at the coding, and i think without the concrete dump it will be very difficult to find the problem. this code we haven't changed for a long time and it's the first time i see the error.  i will also give it a try with some _16 vm dumps to see if i can get this reproduced. (in reply to <a href="show_bug.cgi?id=294311#c1">comment #1</a>) <span class="quote">&gt; does this happen also with smaller dumps? i'm asking as it would be very &gt; helpful to have a heap dump which triggers the problem and look at it. or could &gt; you provide us this dump (i guess zipped it will be about 100 - 150mb). may be &gt; you can upload it somewhere? &gt;  &gt; i had a look at the coding, and i think without the concrete dump it will be &gt; very difficult to find the problem. this code we haven't changed for a long &gt; time and it's the first time i see the error. &gt;  &gt; i will also give it a try with some _16 vm dumps to see if i can get this &gt; reproduced.</span >  i too am seeing this with my dump, in this case a 44 meg phd file generated from both linux and windows; somewhere in &quot;calculating dominator tree&quot;. i'm looking at phd files on a window 2003 server; they we generated on a linux redhat box and a separate 2003 server.  i might be able to get you this file(phd) if you think it helpful; i'd have to ask around, sometimes ibm is picky about these things.  i can certainly run tests for you.   directory of i:\dumps  11/09/2009  04:21 pm    &lt;dir&gt;          . 11/09/2009  04:21 pm    &lt;dir&gt;          .. 11/09/2009  04:21 pm         6,169,204 heapdump...a2s.in dex 11/09/2009  04:21 pm        23,724,473 heapdump...idx.in dex 11/09/2009  04:21 pm        36,216,168 heapdump...inboun d.index 11/09/2009  04:21 pm         4,820,628 heapdump...index 11/09/2009  04:21 pm         9,301,574 heapdump...o2c.in dex 11/09/2009  04:21 pm        36,091,168 heapdump...outbou nd.index 11/09/2009  04:17 pm        44,057,804 heapdump...phd 11/09/2009  04:20 pm                 0 heapdump...thread s                8 file(s)    160,381,019 bytes                2 dir(s)  952,665,055,232 bytes free  java.lang.arrayindexoutofboundsexception org.eclipse.mat.parser.internal.dominatortree$calculator.dfs(dominatortree.java:  org.eclipse.mat.parser.internal.dominatortree$calculator.compute(dominatortree.java:  org.eclipse.mat.parser.internal.dominatortree.calculate(dominatortree.java:  org.eclipse.mat.parser.internal.snapshotimpl.calculatedominatortree(snapshotimpl.java:  org.eclipse.mat.parser.internal.snapshotfactoryimpl.parse(snapshotfactoryimpl.java:  org.eclipse.mat.parser.internal.snapshotfactoryimpl.opensnapshot(snapshotfactoryimpl.java:  org.eclipse.mat.snapshot.snapshotfactory.opensnapshot(snapshotfactory.java:  org.eclipse.mat.snapshot.snapshotfactory.opensnapshot(snapshotfactory.java:  org.eclipse.mat.ui.snapshot.parseheapdumpjob.run(parseheapdumpjob.java:  org.eclipse.core.internal.jobs.worker.run(worker.java:   eclipse.buildid=unknown java.fullversion=jre .0 ibm j9  windows server 2003 x86-32 jvmwi3260sr6-20090923_42924 (jit enabled, aot enabled)  using the standalone version i installed today eclipse memory analyzer version  (c) copyright eclipse contributors 2009.  all rights reserved.  thanks! created <span class=""><a href="attachment.cgi?id=151798&amp;action=diff" name="attach_151798" title="patch to dump the sizes of some important internal structures">attachment 151798</a> <a href="attachment.cgi?id=151798&amp;action=edit" title="patch to dump the sizes of some important internal structures">[details]</a></span> patch to dump the sizes of some important internal structures created <span class=""><a href="attachment.cgi?id=151799" name="attach_151799" title="mylyn/context/zip">attachment 151799</a> <a href="attachment.cgi?id=151799&amp;action=edit" title="mylyn/context/zip">[details]</a></span> mylyn/context/zip created <span class=""><a href="attachment.cgi?id=151800" name="attach_151800" title="built bundle containing a patch to dump the sizes of some internal structures">attachment 151800</a> <a href="attachment.cgi?id=151800&amp;action=edit" title="built bundle containing a patch to dump the sizes of some internal structures">[details]</a></span> built bundle containing a patch to dump the sizes of some internal structures i would very much appreciate if one of you can let me download a problematic heap dump. i had meanwhile a more detailed look at the coding. it seems that we either we wrongly calculate the number of objects in the heap (provided later by the snapshotinfo object), or that while cleaning some unreachable objects we have &quot;forgotten&quot; an id of such an object somewhere. these ids are used later as indexes to access some arrays, and therefore could be the cause of the problem.  if providing the dump to us is difficult, i would be thankful if you can execute the same steps again with the attached patch. i have also build the plugin, so that you can temporarily replace your old one. the patch will not solve the problem. it will just print the sizes of some important structures, so that i know if the problem is wrongly calculated size, or wring content. this can give me some further hints.  these are the steps you could follow: - move the org.eclipse.mat.parser_*.jar out of the &lt;mat&gt;/plugins/ directory, and replace it with the attached one - delete the old log file &lt;mat&gt;/workspace/.metadata/.log - delete the indexes of the heap dump - start mat and open the heap dump - send me back the newly generated &lt;mat&gt;/workspace/.metadata/.log file  i will probably not be able to solve the problem directly after this step, but i hope to get closer to it.  thanks for your time and feedback! created <span class=""><a href="attachment.cgi?id=151814" name="attach_151814" title="the .log with the debug patch.">attachment 151814</a> <a href="attachment.cgi?id=151814&amp;action=edit" title="the .log with the debug patch.">[details]</a></span> the .log with the debug patch.  cleaned the indexes, ran... same results as expected.  i can see the stack trace has different line numbers, so it look like you patch did get picked up. thanks for running the test! the problem seems to be that i am getting wrong value from snapshot.getsnapshotinfo().getnumberofobjects() - one object less than the values in the indexes. in the log file:  ... !message snapshot.getsnapshotinfo().getnumberofobjects() = 3382369 ... !message snapshot.getindexmanager().idx.size() = 3382370 ...  i will look now in more detail how we calculated this and what could go wrong there.  can you try to zip and send me the &lt;heapdump&gt;.index and &lt;heapdump&gt;.o2c.index files? i hope this is not a problem (except the size), as they contain no sensitive data. the first one contains the serialized snapshotinfo object, and serialized data for every class from the heap dump. the second contains a mapping objectid to class id. this could help me, but i would understand if you can't (or are not allowed) to send them.  i hope next time i'll be able to send you a patch which fixes the problem. created <span class=""><a href="attachment.cgi?id=151843" name="attach_151843" title="the &lt;heapdump&gt;.index  and .log file">attachment 151843</a> <a href="attachment.cgi?id=151843&amp;action=edit" title="the &lt;heapdump&gt;.index  and .log file">[details]</a></span> the &lt;heapdump&gt;.index  and .log file  i also added the .log, since i needed to rerun the test; so it should all match up.  i think i'll be able to provide a dmp, but from our released product; i'll check into that in a few minutes.  i'll send the other file in separate attachment, as it's too large to combine for bugzilla.  have you got an address i can upload a large file too? created <span class=""><a href="attachment.cgi?id=151844" name="attach_151844" title="the &lt;heapdump&gt;.o2c.index file">attachment 151844</a> <a href="attachment.cgi?id=151844&amp;action=edit" title="the &lt;heapdump&gt;.o2c.index file">[details]</a></span> the &lt;heapdump&gt;.o2c.index file  off by one error!!; happens to me all the time :) i have a heap dump i can send you, 45 megs compressed.  if you can let me know a server, i'll upload it for you.  i don't have an easy way for you too pull it from here.  thanks! thanks for the logs and indexes! i have created a container for you, where you can upload the .phd file per http. it is possible to upload just one file there. if something goes wrong, i'll open another one. <a href="https://sapmats-de.sap-ag.de/upload/index.cgi?id=lwdjxgldd2f5bkb649au04awsvgfbaz9u15s3jr8870tucrc1u">https://sapmats-de.sap-ag.de/upload/index.cgi?id=lwdjxgldd2f5bkb649au04awsvgfbaz9u15s3jr8870tucrc1u</a> ok!  sent, let me know if you didn't get it, and we can try again.  the browser (chrome) seemed to think things went well. i got the file. surprizing for me i was able to parse it without problems.  i guess we may have different versions of the dtfj implementation. can you list the contents of the &lt;mat&gt;/plugins folder and send me the names of all com.ibm.dtfj.* ?  i will try meanwhile to use the indexes you provided to analyze the root cause. here you go! latest i could find...  09/29/2009  01:56 pm            17,494 com.ibm.dtfj.api_..jar 09/29/2009  01:56 pm           743,251 com.ibm.dtfj.j9_..jar 09/29/2009  01:56 pm           126,756 com.ibm.dtfj.phd_..jar 09/29/2009  01:56 pm           901,681 com.ibm.dtfj.sov_..jar i was thinking it might be my system,... so i installed it all on a fresh vm of w2k3, with a late version jre, and using the same phd, i had the same exception occur.  don't know why you don't see it... maybe you could send your jars to see if that's it?  i really need that output!  thanks,    andrew  e:\mat\mat&gt;java -version java version &quot;.0&quot; java(tm) se runtime environment (build pwi3260sr6-20090925_01(sr ) ibm j9 vm (build , jre .0 ibm j9  windows server 2003 x86-32 jvmwi3260s r6-20090923_42924 (jit enabled, aot enabled) j9vm - 20090923_042924 jit  - r9_20090902_1330ifx1 gc   - 20090817_aa) jcl  - 20090924_01 i had a buddy with these versions of the files, and they seem to work. so the bug was introduced post these guys.   s:\mat\mat\plugins&gt;xcopy d:\downloads\com.ibm.dtfj.* . d:\downloads\com.ibm.dtfj.api_..jar d:\downloads\com.ibm.dtfj.j9.impl_..jar d:\downloads\com.ibm.dtfj.phd_..jar d:\downloads\com.ibm.dtfj.sov.impl_..jar 4 file(s) copied it turned out that andrew has already made some changes so that with the latest dtfj the problem doesn't appear. but these changes weren't included in the last version published on our download page.  i have also made some changes to get the correct number of objects in case of mismatch. this should prevent the error in the dominator tree  calculation, and hopefully also solve the originally reported problem (which was with an .hprof heap dump).  on our download page now there is a new version available, which contains both changes. you can try our if it solves the problem with the .phd dump, but also the originally reported problem with the hprof dump.  i'll be happy to get some confirmation if this helped. is this now fixed? i think this is fixed now. closing the bug. (array index out of bounds exception ) (dominator tree ) (dominator tree ) (dominator tree ) (dominator tree ) (dominator tree ) (dominator tree ) (snapshot impl ) (snapshot impl ) (snapshot factory impl ) (snapshot factory impl ) (snapshot factory impl ) (snapshot factory impl ) (snapshot factory ) (snapshot factory ) (snapshot factory ) (snapshot factory ) (parse heap dump job ) (parse heap dump job ) (array index out of bounds exception ) (dominator tree ) (dominator tree ) (dominator tree ) (dominator tree ) (dominator tree ) (dominator tree ) (snapshot impl ) (snapshot impl ) (snapshot factory impl ) (snapshot factory impl ) (snapshot factory impl ) (snapshot factory impl ) (snapshot factory ) (snapshot factory ) (snapshot factory ) (snapshot factory ) (parse heap dump job ) (parse heap dump job ) (snapshot info ) (i ds ) (snapshot info ) ( x ) ( 11 ) ( x ) ( 86 ) ( c ) ( 1 ) ( j ) ( 9 ) ( x ) ( 86 ) ( j ) ( 9 ) ( sr ) ( 6 ) ( j ) ( 9 ) ( j ) ( 9 ) ( x ) ( 86 ) ( r ) ( 6 ) ( r ) ( 9 ) ( j ) ( 9 ) 294311 294311 294311 294311